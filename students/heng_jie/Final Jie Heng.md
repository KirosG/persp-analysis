# Final ExamMACSS 30000Jie Heng### Task 1 and Task 2 Summarize and Evaluate research design respectively### Ariticle 1. Digital Discrimination: The case of Airbnb.com### Part 1: research design and computational methods**Research question:**This paper seeks to answer the following questions:1. Does racial discrimination affect the guests' behavior in Airbnb?2. Which factor determines the price of properties?**Research design:**This paper conducted an observational study.(1) Data collectionThrough Airbnb.com, the research team obtained the pictures of New York City landlords and the properties on Airbnb along with rental prices on July 17, 2012. They also saved the information about hosts reviews and rating. (2) MethodsTo evaluate the quality of the listings and identify the race of hosts, Mturk workers were hired to perform two tasks, examine and rate the listing’s photos on a seven-points scale, and distinguish the race of hosts. Regression was used to analyze potential factors that influence the price of the listing, such as the location of the listings, quality, size, the role of pictures and race of hosts. Then, by comparing the renting prices of non-black hosts and black hosts, the researchers computed the average price of rents of two groups. To examine if race is the main determinants of price, researchers controlled for all information that a guest sees when examining Airbnb search results and listing details to observe the change of racial price gap.**Computational methods:**The study used mass collaboration: MTurk to deal with the raw data. Mturk workers were provided the pictures of listing and hosts and asked to rate the quality of listing and identify the race of the hosts. Researchers broke the research into two simple pieces, rating and identifying, sent them to MTurk workers, and then aggregate the results. This method saves the researchers' time and increase their efficiency by sending easy-conducted and tedious tasks to MTurk workers. Research thus can be more concentrated on answering the research questions.The data was collected through an online platform, Airbnb. Without human intervention, this data reflects the real world activity. It also motivates the workers to come up questions like why this platform is different from others, like eBay and ask more interesting and valuable questions. For sure, this research is an example of big data, the advantages and disadvantages are discussed in the evaluation part. ### Part 2: Evaluation **Effectiveness:**Non-reactive is significant in this research. As the hosts were not aware of this research, they could not hide their discriminatory preferences, which ensures that the result is convincing. Plus, by hiring MTurk worker and using open data, the research are free from dealing with dirty raw data and worrying the sensitivity issue.  **Limitation**(1) Big data:The biggest issue of this research is its sample. Collecting data only in one city and only in a single day results in sample bias. New York is a metropolis and the date the researchers chose was in summer vacation. I doubt the application of the conclusion of this paper in other cities and in other seasons. This research fails to take advantage of the benefits of big data: always-on and big, and thus it is also not representative.(2) Causal mechanisms:As this is a observational study, it fails to explain why non-black hosts more than black hosts even if the listings are of the same quality.### Aricle2: Rapid Discrimination in the Sharing Economy: Evidence from a Field Experiment### Part 1: research design and computational methods**Research question:**1. How does racial discrimination influence the rate of acceptance of the host?2. Does other factors mitigate the discrimination? Factors include hosts characteristics (gender, race, age, the type and size of the hosts’property, hosts' experience in Airbnb), listing characteristics (the cost and the location of the property).3. Do all hosts have obvious racial discrimination? 4. How much does discrimination cost hosts? **Research design:****Digital experiment** The study conducted a digital experiment in July 2015 to answer the first research question. (1) Sample and data sourceResearchers created 20 Airbnb accounts and sent inquiry emails to all hosts on Airbnb (6,400 listings) in five cities eight weeks before the inquired renting date. The accounts (five African American female, five African American male, five White female, five White male) only showed the guests’ name, without a picture. The researchers conducted the experiment in five cities, Baltimore, Dallas, Los Angeles, St. Louis and Washington, DC-- cities are chosen based on the levels of Airbnb usage. If the hosts have multiple properties, the inquiry was randomly sent to ask only one of the hosts’ property. Each host only received one inquiry email. Only hosts whose properties were available during the weekend in question will be included in this research.(2) pre-experiment surveyA pre-experiment survey was conducted to evaluate whether the research groups chose appropriate and typical African American male’s and female’s names, and White male’s and female's names.(3) Treatment group and delivery of treatmentFour treatment groups are designed:*  Hosts received an inquiry email from a guest with an African American male's name*  Hosts received an inquiry email from a guest with an African American female's name*  Hosts received an inquiry email from a guest with a White male's name*  Hosts received an inquiry email from a guest with a White female's nameTreatment was delivered by email.(4) MeasurementAfter the treatment was delivered, the research team recorded the hosts’ response to the inquiry email and only ‘yes’ will be considered as the accept of the inquiry instead of ‘vague’ answers, such as ‘yes’ but with questions. Then the researchers calculated the proportion of hosts accept the inquiry in each treatment groups. **Experiment combined with an observational study**The observational study provided more detailed information (pre-treatment information) about the hosts, which used to exclude confounders in the experiment. By conducting the observational study, the researchers were able to answer the second to fourth research questions.(1) Data sourceInformation about hosts characteristics, listing characteristics and other related data were obtained from Airbnb’s profile page, listings and census demographic data.(2) Methodsa. detecting in-group biasResearchers divided the participants into various subgroups according to different characteristics and then calculated the response rate in different groups. Regression model was used. For example, to examine whether homophily affects the result, researchers divided hosts into two groups: African American hosts and hosts from different races, then they built regression model that included guest race and host race and interaction term to compute the acceptance rates and compare with the rate they got in the experiment. b. comparing experimental results with observational patternsThe research team gathered the ten most recent reviews on hosts’ listing page. Then they filtered and counted the reviews from African American guests, followed by comparing the acceptance rates between hosts who had received African American guests and those had not. c. counting cost of discriminationResearchers observed the participants after eight weeks to see if the hosts once rejected the inquiry found a replacement test. By applying Net Revenue formula, they computed the cost of discrimination to answer the fourth question.**Computational methods**Mturk and Face++ were used to identify the gender, race and age of hosts and guests respectively. Mturk workers were provided with profile pictures of hosts and they categorized hosts into different groups, which was used to analyze the in-group bias. Researchers applied Face ++ to filter the past African American guests of a host by race, gender, and age. In addition, researchers used web browser automation tools to deliver treatment and digital scrapers to gather hosts’information. These three methods saves researchers' time and helps researchers to answer research question.As for the influence of computational methods on asking questions, similar to the first study, the computational methods help the researchers to detect and explore the questions.### Part 2: Evaluation **Effectiveness**The research tries to find if there is a causal relationship between racial discrimination among hosts and acceptance rates in Airbnb. Researchers also take confounders, such as hosts’ gender, age and other factors into consideration. The research is fairly effective considering the following reasons.(1) Big dataAll participants were unaware of they were observed, which ensures that no hosts will act differently and the result is convincing. In addition, as all Airbnb hosts can be viewed online at ease, researchers can reach all of them without additional costs. The digital age helps researchers to conduct the research on a fairly large sample, avoiding the potential error and bias caused by small sample size. Although dirty is a drawback of big data, we could learn from the approach the research team used to handle it. The hosts’ responses to the email were messy. However, the way the researchers used to deal with the data was impressive. They decided to only consider the simplest ‘yes’ as acceptance and provided convincing reasons to support their decision.While researchers can only find limited information about hosts on Airbnb, the researchers combined other sources of data to complete this research. For example, to obtain the location of the property, the researchers combined census demographic data to find the relationship between neighborhood demographics and discrimination.(2) Experiment validityThe experiment was statistically valid as it used statistical model, for instance, regression to compute the results. The researchers also ensured the study's internal validity as they used computational methods in randomization, delivery of the treatment, and measurement of outcomes to reduce concerns. As for the external validity, the researchers chose a fairly large sample and they took other online platform into consideration, by comparing the result of their study with studies on eBay. What’s more, they also used the hosts’ past guests’ information to clarify the result might not be applied on people with a history of accepting African American. (3) Heterogeneity of treatment effects:The experiment is a within-subjects study, which designs the behavior of participants is compared before and after the treatment. Thus, researchers knew well about the hosts and they could estimate heterogeneity of treatment effects. They used their hosts’ past guests' information to examine the how treatment work and examine the external validity.(4) Causal mechanisms:The researchers not only found the casual relations between racial discrimination and acceptance rates in Airbnb, but also tested other factors that might influence this casual relation.**Limitation**The drawbacks of big data is the biggest limitation of this paper.(1) Big dataSystem drifting imposed negative impacts on this research. Since Airbnb blocked the guest accounts created by the research team, the research had to stop. With a longer period, the researchers might be able to answer questions they failed to answer in this paper, like whether the discrimination is based on race, socioeconomic status, or a combination of the two, profile picture's role in the inquiry. ### Task 3 Advantages of conducting an experiment and an observational study:Both paper provides valuable information and findings. By combining these two studies together, readers can get a broader picture of racial discrimination in online platform.Both studies are designed to analyze racial discrimination on Airbnb, but they are from different aspects. In the observational study that conducted in 2014, researchers mainly discussed the influence of hosts’ race and other characteristics of listings on the rents. In another word, it studies that whether there is racial discrimination towards hosts on Airbnb. In the second paper, the researchers consider the same issue from another point of view—it examines the racial discrimination behavior of hosts. Combined this two research, we could draw a conclusion that racial discrimination does exist in Airbnb, and it exists in both demand side and supply side. In addition, the two studies together expand the application of the research findings and strengthen the validity of the research. As I describe in the limitation part of the first study, sample bias is the main concern of this research. However, by conducting the experiment, researchers could convince the readers that racial discrimination does not only exist in one city-- it is quite common in the United States. The first observational study also has some benefits that the second study lacks. As the data in the first paper is directly obtained from the real world without intervention, it is more persuasive than the experiment and the validity could be strengthened if we the two studies are combined.What’s more, casual relation becomes more obvious. The experiment has greater explanatory power than the first one. But this does not mean the first study is not necessary. The data in the first study can support the casual relations and make it more convincing.Conducting only one of them, we would only get partial information about the racial discrimination on Airbnb and the limitation cannot be alleviated or reduced. Generally, the experiments and observational study together, provide a full picture of racial discrimination on Airbnb, and make the finding more persuasive, as the application is expanded, validity is strengthened and casual relations is more obvious.  ### Task 4 Digital Survey ResearchThe primary question of interest from the two paper is that whether racial discrimination exist on Airbnb of both the demand and the supply side. To answer this question, I would conduct a survey on Amazon MTurk.  As Airbnb has already shown a negative attitude on the research, it is not likely to conduct a survey on Airbnb users directly. Thus, I plan to recruit workers on MTurk to be the participants of the survey. The survey will be conducted online and designed to complete in five minutes. MTurk workers will be randomly divided into two groups and be provided with two different survey. One is designed from demand side; the other is from the supply side. At the beginning of the survey, it will state that‘assuming you are an Airbnb host’or‘assuming you are an Airbnb guest'. Then, the survey will provide participants with information about the potential Airbnb guests or hosts.If the participants are assigned to be a fake Airbnb host, the information the MTurk workers get is similar with the email in the second paper (2017), the name of each guest is the only available information to participants. The survey will use the same guest names in the experiment study, including five African American females’ names, five African American males’ names, five White females’ names, five White males’ names. Each time, two potential guests’ information will randomly pop up on the screen, participants are required to choose their potential guest in five seconds. The participants will only receive five pair of names. Then, they are required to answer one question:If you are an Airbnb host, which three characteristics of your potential guests that you think is the most important? If your answer is not listed below, please write them on the line. A. age  B. race C. gender D. personality _______________If the participants are assigned to be a fake Airbnb guest, the information the MTurk workers get is more complex. Along with the name of the hosts, participants will also know the characteristics of the listing, including the listing ‘s price, location, type and picture. I will use the listing information that has already been analyzed by the first observational study. Each time, two potential hosts’ names and two the listing information will also randomly pop up on the screen, the listing information will also be randomly mapped with the names. The quality of the listing and its mapped names will be stored in the database for future analysis. Each participant is required to choose their potential host in five seconds. The participants will only receive five pair of names. Then, they are required to answer one question similar with the other group. If you are an Airbnb host, which three characteristics of your potential guests that you think is the most important? If your answer is not listed below, please write them on the line. A. location  B. race C. price D. type of the property _______________To measure this survey, regression and other statistic methods will be used. After analysis, the most significant determinant factors in the host and guest groups could be computed.One potential error is that participants might figure out the aim of this research and hide their real while answering questions. One possible solution is that the survey could add one or two unrelated questions to ‘confuse’ the participants.  Another error is sampling error. The participants’ race might influence the results. If there are much more black participants than the white participants, the result of this survey might be the opposite to the two studies. To overcome this drawback, I would conduct a survey with a large sample size. Ideally, this survey could recruit more than 6,000 MTurk worker. At the beginning of this survey, participants will be asked to fill out the basic information, including their race. They are also allowed to not tell their race. After the survey, I would filter the participants or weigh the result based on the proportion of African Americans and White participants.